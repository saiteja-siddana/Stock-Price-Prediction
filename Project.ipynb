{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86be2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 03:48:42.266214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import pandas as pd      \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90516843",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = 'Cisco'\n",
    "close_price_as_predictive_column = False\n",
    "\n",
    "start_date = datetime.strptime('03/02/2020', '%m/%d/%Y')\n",
    "end_date = datetime.strptime('03/03/2023', '%m/%d/%Y')\n",
    "\n",
    "data = []\n",
    "\n",
    "with open('Historical Data/' + company_name + '.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    next(csv_reader)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        date_str = row[0]\n",
    "        date = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "        if start_date <= date <= end_date:\n",
    "            data.append(row)\n",
    "\n",
    "rows = list(data)\n",
    " \n",
    "averages = []\n",
    "for i in range(0, len(rows), 5):\n",
    "    row_subset = rows[i:i+5]\n",
    "    col_subset = [float(row[1][1:]) for row in row_subset]\n",
    "    avg = sum(col_subset) / len(col_subset)\n",
    "    averages.append(round(avg,2))\n",
    "\n",
    "processed_data = []\n",
    "processed_data.append(['Date', 'Close', 'Layoffs'])\n",
    "for i in range(0, len(rows), 5):\n",
    "    row_subset = rows[i:i+5]\n",
    "    first_row = row_subset[0][0]\n",
    "    mapped_avg = averages[int(i/5)]\n",
    "    date = datetime.strptime(first_row, '%m/%d/%Y')\n",
    "    processed_data.append([first_row, mapped_avg,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27800969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cisco', 'SF Bay Area', 'Infrastructure', '4100', '0.05', '2022-11-16', 'Post-IPO', 'United States', '2.0']\n"
     ]
    }
   ],
   "source": [
    "companies = ['Adobe', 'Airbnb', 'Amazon', 'Apple', 'Atlassian', 'Cisco', 'Coinbase', 'Goldmansachs', 'Google', 'IBM', 'Intel', 'Intuit', 'Meta', 'Microsoft', 'Netflix', 'Oracle', 'Salesforce', 'SAP', 'Uber', 'Walmart']\n",
    "\n",
    "with open('layoffs.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    \"\"\"\n",
    "    for row in csv_reader:\n",
    "        if row[0] in companies:\n",
    "            print(row)\n",
    "    \"\"\"\n",
    "\n",
    "            \n",
    "sorted_rows = sorted(rows, key=lambda x: x[0])\n",
    "\n",
    "processed_rows = list(processed_data)\n",
    "\n",
    "start = 1\n",
    "\n",
    "for row in sorted_rows:\n",
    "    if (row[0] == company_name):\n",
    "        print(row)\n",
    "        date = datetime.strptime(row[5], '%Y-%m-%d')\n",
    "        for i in range(start,len(processed_rows)-1):\n",
    "            second_date = datetime.strptime(processed_rows[i][0], '%m/%d/%Y')\n",
    "            first_date = datetime.strptime(processed_rows[i+1][0], '%m/%d/%Y')\n",
    "            if second_date == date:\n",
    "                processed_data[i][2] = int(row[3])\n",
    "                start = i\n",
    "            else:\n",
    "                if first_date == date:\n",
    "                    processed_data[i+1][2] = int(row[3])\n",
    "                    start = i\n",
    "                else:\n",
    "                    if first_date < date < second_date and row[3].isdigit():\n",
    "                        processed_data[i+1][2] = int(row[3])\n",
    "                        start = i\n",
    "                \n",
    "                \n",
    "with open('Processed Data/' + company_name + '.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for row in processed_data:\n",
    "        csv_writer.writerow(row)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3984463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ({'ssr_ftest': (0.19506614726493515, 0.6593777627979982, 148.0, 1), 'ssr_chi2test': (0.19902019079057573, 0.6555128848116205, 1), 'lrtest': (0.19888915017054387, 0.655618989966779, 1), 'params_ftest': (0.19506614726478214, 0.6593777627981194, 148.0, 1.0)}, [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefa1370f10>, <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefa1370370>, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (1.8492376661899852, 0.16104890830951132, 145.0, 2), 'ssr_chi2test': (3.8260089645310043, 0.14763614938565114, 2), 'lrtest': (3.7780286520187474, 0.15122078980032644, 2), 'params_ftest': (1.8492376661899415, 0.16104890830951787, 145.0, 2.0)}, [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefd243dca0>, <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefd243d850>, array([[0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (1.2553797315704955, 0.2921240011913806, 142.0, 3), 'ssr_chi2test': (3.95179394374656, 0.26671678319343484, 3), 'lrtest': (3.900297537190454, 0.27243340912215636, 3), 'params_ftest': (1.2553797315704842, 0.2921240011913826, 142.0, 3.0)}, [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefd243d7c0>, <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefd243dc70>, array([[0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (1.1276045345161594, 0.34605749923378787, 139.0, 4), 'ssr_chi2test': (4.802459600241485, 0.30817338133477945, 4), 'lrtest': (4.726187555447723, 0.3165631724820432, 4), 'params_ftest': (1.1276045345161352, 0.34605749923379747, 139.0, 4.0)}, [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefa13e40d0>, <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fefa13e41f0>, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}\n",
      "Lag 1:\n",
      "F-test p-value: 0.6593777627981194\n",
      "Chi-squared p-value: 0.6555128848116205\n",
      "\n",
      "\n",
      "Lag 2:\n",
      "F-test p-value: 0.16104890830951787\n",
      "Chi-squared p-value: 0.14763614938565114\n",
      "\n",
      "\n",
      "Lag 3:\n",
      "F-test p-value: 0.2921240011913826\n",
      "Chi-squared p-value: 0.26671678319343484\n",
      "\n",
      "\n",
      "Lag 4:\n",
      "F-test p-value: 0.34605749923379747\n",
      "Chi-squared p-value: 0.30817338133477945\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Processed Data/' + company_name + '.csv')\n",
    "\n",
    "ts1 = df.iloc[:, 1]\n",
    "ts2 = df.iloc[:, 2]\n",
    "\n",
    "results = grangercausalitytests(df[['Layoffs', 'Close']], maxlag=4, verbose=False)\n",
    "\n",
    "print(results)\n",
    "\n",
    "for lag in range(1, 5):\n",
    "    print(f'Lag {lag}:')\n",
    "    print(f'F-test p-value: {results[lag][0][\"params_ftest\"][1]}')\n",
    "    print(f'Chi-squared p-value: {results[lag][0][\"ssr_chi2test\"][1]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a558a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[::-1]\n",
    "df['Pct_Change'] = round(df['Close'].pct_change(periods=1)*100,2)\n",
    "if df['Pct_Change'].isnull().values.any():\n",
    "    df['Pct_Change'] = df['Pct_Change'].fillna(0)\n",
    "\n",
    "def direction(row):\n",
    "    if(row['Pct_Change'] < 0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['Direction_Change'] = df.apply(direction, axis=1)\n",
    "\n",
    "#print(df)\n",
    "df.to_csv('Processed Data/' + company_name + '.csv', index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d552d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21648598470263977\n",
      "R2 score: 1.00\n"
     ]
    }
   ],
   "source": [
    "X = df[['Layoffs','Close']]\n",
    "y = df['Close']\n",
    "#y = df['Pct_Change']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 score: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac34b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Close  Layoffs  Pct_Change  Direction_Change\n",
      "0    03/04/2020  40.87        0        0.00                 1\n",
      "1    03/11/2020  38.87        0       -4.89                -1\n",
      "2    03/18/2020  35.43        0       -8.85                -1\n",
      "3    03/25/2020  36.84        0        3.98                 1\n",
      "4    04/01/2020  39.47        0        7.14                 1\n",
      "..          ...    ...      ...         ...               ...\n",
      "147  02/02/2023  48.66        0        2.06                 1\n",
      "148  02/09/2023  47.55        0       -2.28                -1\n",
      "149  02/16/2023  48.45        0        1.89                 1\n",
      "150  02/24/2023  49.49        0        2.15                 1\n",
      "151  03/03/2023  48.66        0       -1.68                -1\n",
      "\n",
      "[152 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Processed Data/' + company_name + '.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c1fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21066426],\n",
       "       [-1.53480748],\n",
       "       [-2.09233381],\n",
       "       [-1.86381284],\n",
       "       [-1.43756451],\n",
       "       [-1.26576861],\n",
       "       [-1.08586912],\n",
       "       [-1.06155838],\n",
       "       [-0.90434892],\n",
       "       [-1.14907705],\n",
       "       [-0.85410672],\n",
       "       [-0.57372283],\n",
       "       [-0.40840979],\n",
       "       [-0.22364816],\n",
       "       [-0.30306325],\n",
       "       [-0.40678908],\n",
       "       [-0.4797213 ],\n",
       "       [-0.35006401],\n",
       "       [-0.35492616],\n",
       "       [-0.30954611],\n",
       "       [-0.22040673],\n",
       "       [-0.25930391],\n",
       "       [-0.12154304],\n",
       "       [-0.61910288],\n",
       "       [-1.00807475],\n",
       "       [-0.99835045],\n",
       "       [-1.15069776],\n",
       "       [-1.33383868],\n",
       "       [-1.3857016 ],\n",
       "       [-1.58667039],\n",
       "       [-1.55911822],\n",
       "       [-1.37759802],\n",
       "       [-1.40028804],\n",
       "       [-1.63529187],\n",
       "       [-2.00319443],\n",
       "       [-1.73253484],\n",
       "       [-1.22849214],\n",
       "       [-1.10207628],\n",
       "       [-0.84438242],\n",
       "       [-0.64179291],\n",
       "       [-0.62882718],\n",
       "       [-0.56723997],\n",
       "       [-0.59479214],\n",
       "       [-0.62720647],\n",
       "       [-0.47323844],\n",
       "       [-0.52672207],\n",
       "       [-0.49916989],\n",
       "       [-0.18961312],\n",
       "       [-0.14909522],\n",
       "       [-0.40516836],\n",
       "       [-0.45865199],\n",
       "       [-0.33547757],\n",
       "       [ 0.10697792],\n",
       "       [ 0.18801373],\n",
       "       [ 0.49594979],\n",
       "       [ 0.58995132],\n",
       "       [ 0.5478127 ],\n",
       "       [ 0.62560707],\n",
       "       [ 0.51377766],\n",
       "       [ 0.44408687],\n",
       "       [ 0.70502216],\n",
       "       [ 0.71474646],\n",
       "       [ 0.75202293],\n",
       "       [ 0.74716078],\n",
       "       [ 0.95461244],\n",
       "       [ 0.89626666],\n",
       "       [ 0.72447076],\n",
       "       [ 0.76660937],\n",
       "       [ 0.81361014],\n",
       "       [ 0.85250733],\n",
       "       [ 0.92706027],\n",
       "       [ 1.11020119],\n",
       "       [ 1.20096129],\n",
       "       [ 1.23499632],\n",
       "       [ 1.33710144],\n",
       "       [ 1.74228046],\n",
       "       [ 1.76497049],\n",
       "       [ 1.6353132 ],\n",
       "       [ 1.41975796],\n",
       "       [ 1.25444492],\n",
       "       [ 1.07292472],\n",
       "       [ 1.03564825],\n",
       "       [ 1.07940758],\n",
       "       [ 1.17340911],\n",
       "       [ 1.25120349],\n",
       "       [ 1.45055157],\n",
       "       [ 1.43758584],\n",
       "       [ 1.08751116],\n",
       "       [ 1.11506333],\n",
       "       [ 1.32089428],\n",
       "       [ 1.57210527],\n",
       "       [ 1.9578357 ],\n",
       "       [ 2.36625616],\n",
       "       [ 2.26901319],\n",
       "       [ 2.16042521],\n",
       "       [ 1.87517918],\n",
       "       [ 1.23013418],\n",
       "       [ 1.17665055],\n",
       "       [ 1.13775336],\n",
       "       [ 0.96109531],\n",
       "       [ 1.19934057],\n",
       "       [ 1.2123063 ],\n",
       "       [ 1.08913188],\n",
       "       [ 1.1717884 ],\n",
       "       [ 1.11506333],\n",
       "       [ 1.18637484],\n",
       "       [ 1.04861397],\n",
       "       [ 0.56564058],\n",
       "       [ 0.62398636],\n",
       "       [ 0.25932524],\n",
       "       [ 0.24960094],\n",
       "       [ 0.10859864],\n",
       "       [-0.47810058],\n",
       "       [-0.59155071],\n",
       "       [-0.47161772],\n",
       "       [-0.74227731],\n",
       "       [-0.7617259 ],\n",
       "       [-0.80872667],\n",
       "       [-0.92703894],\n",
       "       [-0.88003818],\n",
       "       [-0.75524304],\n",
       "       [-0.60937859],\n",
       "       [-0.48782488],\n",
       "       [-0.48134202],\n",
       "       [-0.18475097],\n",
       "       [-0.11506018],\n",
       "       [-0.48134202],\n",
       "       [-0.53482565],\n",
       "       [-0.66934508],\n",
       "       [-1.05021337],\n",
       "       [-1.25442359],\n",
       "       [-1.12800774],\n",
       "       [-1.366253  ],\n",
       "       [-1.0437305 ],\n",
       "       [-0.62720647],\n",
       "       [-0.57858498],\n",
       "       [-0.58992999],\n",
       "       [-0.43109982],\n",
       "       [-0.02105865],\n",
       "       [ 0.17180657],\n",
       "       [ 0.05835644],\n",
       "       [ 0.01945926],\n",
       "       [-0.14099164],\n",
       "       [-0.12964662],\n",
       "       [ 0.00325209],\n",
       "       [-0.07778371],\n",
       "       [-0.1069566 ],\n",
       "       [ 0.05187358],\n",
       "       [-0.12802591],\n",
       "       [ 0.01783854],\n",
       "       [ 0.18639301],\n",
       "       [ 0.05187358]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputcols =['Layoffs','Close']\n",
    "outputcols = ['Direction_Change']\n",
    "data = df[inputcols]\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "nlags = 4\n",
    "X = []\n",
    "y = []\n",
    "for i in range(nlags, len(scaled)):\n",
    "    X.append(scaled[i - nlags:i])\n",
    "    if(close_price_as_predictive_column):\n",
    "        y.append(scaled[i,1]) # for close price as a predictive column\n",
    "    \n",
    "\n",
    "if(not close_price_as_predictive_column):\n",
    "    y = np.array(df.loc[nlags:,outputcols]) #for direction change as a predictive column\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(np.array(data.iloc[:, 1]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba96f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 4, 2)\n",
      "(148, 1)\n",
      "(148, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print (y.shape)\n",
    "y = y.reshape([y.shape[0],1])\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97afccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (103, 4, 2)\n",
      "X_test shape :  (45, 4, 2)\n",
      "y_train shape :  (103, 1)\n",
      "y_test shape :  (45, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:103,:,:]\n",
    "X_test = X[103:,:,:]\n",
    "y_train = y[:103,:]\n",
    "y_test = y[103:,:]\n",
    "print('X_train shape : ', X_train.shape)\n",
    "print('X_test shape : ', X_test.shape)\n",
    "print('y_train shape : ', y_train.shape)\n",
    "print('y_test shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8c30fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 03:48:44.799670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4, 64)             17152     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10)                3000      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,163\n",
      "Trainable params: 20,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Neural Network based on LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Adding 1st LSTM layer\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(nlags, len(inputcols))))\n",
    "\n",
    "# Adding 2nd LSTM layer\n",
    "model.add(LSTM(units=10, return_sequences=False))\n",
    "\n",
    "# Adding Dropout\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "if(close_price_as_predictive_column):\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "else:\n",
    "    model.add(Dense(units=1, activation='tanh'))\n",
    "\n",
    "# Compiling the Neural Network\n",
    "if(close_price_as_predictive_column):\n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "else:\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c90b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/6 [====>.........................] - ETA: 12s - loss: -0.0903 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to -2.20356, saving model to weights.h5\n",
      "6/6 [==============================] - 3s 126ms/step - loss: 3.1775 - accuracy: 0.0000e+00 - val_loss: -2.2036 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 3.2869 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss did not improve from -2.20356\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6256 - accuracy: 0.0000e+00 - val_loss: -2.2036 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: -1.1279 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss did not improve from -2.20356\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7905 - accuracy: 0.0000e+00 - val_loss: -2.2036 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.3924 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss improved from -2.20356 to -2.91778, saving model to weights.h5\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8872 - accuracy: 0.0000e+00 - val_loss: -2.9178 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 3.0530 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3304 - accuracy: 0.0000e+00 - val_loss: -0.7277 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.8208 - accuracy: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9452 - accuracy: 0.0000e+00 - val_loss: -2.3751 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.8940 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0320 - accuracy: 0.0000e+00 - val_loss: -0.2386 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.4647 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7071 - accuracy: 0.0000e+00 - val_loss: -0.1626 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1860 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6742 - accuracy: 0.0000e+00 - val_loss: -0.1236 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9995 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6183 - accuracy: 0.0000e+00 - val_loss: -0.1030 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.7319 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5618 - accuracy: 0.0000e+00 - val_loss: -0.0924 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.7586 - accuracy: 0.0000e+00\n",
      "Epoch 12: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.0000e+00 - val_loss: -0.0709 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.2679 - accuracy: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6621 - accuracy: 0.0000e+00 - val_loss: -0.0640 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.7015 - accuracy: 0.0000e+00\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 14: val_loss did not improve from -2.91778\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6302 - accuracy: 0.0000e+00 - val_loss: -0.0620 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train, y_train, shuffle=True, epochs=50, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f2dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "2.2222222222222223\n"
     ]
    }
   ],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 2))\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 2))\n",
    "model.evaluate(X_test, y_test)\n",
    "predictions = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "if(close_price_as_predictive_column):\n",
    "    y_pred = sc_predict.inverse_transform(predictions)\n",
    "    y_pred_train = sc_predict.inverse_transform(predictions_train)\n",
    "else:\n",
    "    predictions[predictions >= 0] = 1\n",
    "    predictions[predictions < 0] = -1\n",
    "    predictions = predictions.astype('int32')\n",
    "\n",
    "print(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506d71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.04      0.07        24\n",
      "           1       0.45      0.90      0.60        21\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.39      0.47      0.34        45\n",
      "weighted avg       0.39      0.44      0.32        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "if(not close_price_as_predictive_column):\n",
    "    print(classification_report(y_test, predictions))\n",
    "else:\n",
    "    plt.rcParams[\"figure.figsize\"] = [10,5]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "    plt.plot(df.loc[:,'Date'], df.loc[:,'Close'], color='b', label='Actual Stock Price')\n",
    "    plt.plot(df.loc[:102,'Date'], y_pred_train, color='orange', label='Training predictions')\n",
    "    plt.plot(df.loc[103+nlags:,'Date'], y_pred, color='r', label='Predicted Stock Price')\n",
    "\n",
    "    plt.xticks(np.arange(0, len(df), 20))\n",
    "\n",
    "    plt.legend(shadow=True)\n",
    "    plt.title(company_name + ' (LO,Close price)',fontsize=12)\n",
    "    plt.xlabel('Timeline', fontsize=10)\n",
    "    plt.ylabel('Stock Price Value', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cc661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
